{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CHUN\\\\Dropbox\\\\Gang Xia-1977\\\\USA life\\\\EDUCATION\\\\MSDS-NWU\\\\7_422-DL_2019_Spring\\\\Week05'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 1 # seed value for random number generator             \n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "import pandas as pd\n",
    "import os #manage files\n",
    "import sklearn \n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score # evaluation metrics\n",
    "from sklearn.preprocessing import StandardScaler # used for variable scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler  # used for variable scaling data\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Read train data set\n",
    "mydata_train=pd.read_csv('train.csv')\n",
    "mydata_test =pd.read_csv('test.csv')\n",
    "print(mydata_train.shape)\n",
    "print(mydata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pd.isnull(mydata_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set:\n",
      "    label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0  1      0       0       0       0       0       0       0       0        \n",
      "1  0      0       0       0       0       0       0       0       0        \n",
      "2  1      0       0       0       0       0       0       0       0        \n",
      "3  4      0       0       0       0       0       0       0       0        \n",
      "4  0      0       0       0       0       0       0       0       0        \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0  0         ...     0         0         0         0         0          \n",
      "1  0         ...     0         0         0         0         0          \n",
      "2  0         ...     0         0         0         0         0          \n",
      "3  0         ...     0         0         0         0         0          \n",
      "4  0         ...     0         0         0         0         0          \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0  0         0         0         0         0         \n",
      "1  0         0         0         0         0         \n",
      "2  0         0         0         0         0         \n",
      "3  0         0         0         0         0         \n",
      "4  0         0         0         0         0         \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "test data set:\n",
      "    pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0  0       0       0       0       0       0       0       0       0        \n",
      "1  0       0       0       0       0       0       0       0       0        \n",
      "2  0       0       0       0       0       0       0       0       0        \n",
      "3  0       0       0       0       0       0       0       0       0        \n",
      "4  0       0       0       0       0       0       0       0       0        \n",
      "\n",
      "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0  0         ...     0         0         0         0         0          \n",
      "1  0         ...     0         0         0         0         0          \n",
      "2  0         ...     0         0         0         0         0          \n",
      "3  0         ...     0         0         0         0         0          \n",
      "4  0         ...     0         0         0         0         0          \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0  0         0         0         0         0         \n",
      "1  0         0         0         0         0         \n",
      "2  0         0         0         0         0         \n",
      "3  0         0         0         0         0         \n",
      "4  0         0         0         0         0         \n",
      "\n",
      "[5 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display structure of train dataset\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(\"train data set:\\n\", mydata_train.head())\n",
    "print(\"test data set:\\n\", mydata_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Begin by fitting a random forest classifier using the full set of 784 explanatory variables and the model training set (train.csv)\n",
    "## Record the time it takes to fit the model and then evaluate the model on the test.csv data by submitting to Kaggle.com\n",
    "## Provide your Kaggle.com score and user ID.\n",
    "\n",
    "### It took about 5 seconds to fit the train data set\n",
    "### ID: michaelxiagang, score = 0.93957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.datetime.now()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# set up response and independent variables \n",
    "X_train=mydata_train.iloc[:, 1:784].values\n",
    "y_train=mydata_train.iloc[:,0].values\n",
    "X_test =mydata_test.iloc[:, :783].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model using train data set and record the time\n",
    "# It took about 5 seconds to fit the train data set\n",
    "clf = RandomForestClassifier(n_estimators=10, max_features = 'sqrt', bootstrap = True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data set \n",
    "# Result was submitted to Kaggle\n",
    "# ID: michaelxiagang, score = 0.93957\n",
    "y_pred=clf.predict(X_test)\n",
    "y_pred1 = pd.DataFrame(y_pred)\n",
    "y_pred1.index = y_pred1.index +1\n",
    "y_pred1.to_csv(\"Xia_Assignment5_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03.340164\n"
     ]
    }
   ],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Execute principal components analysis (PCA) on the combined training and test set data together, \n",
    "## generating principal components that represent 95 percent of the variability in the explanatory variables. \n",
    "## The number of principal components in the solution should be substantially fewer than the 784 explanatory variables. \n",
    "## Record the time it takes to identify the principal components.\n",
    "\n",
    "### IT took about 10 seconds to run each individual PCA analysis\n",
    "### When components is 155 (which is less than 784), explained variability is 0.95042615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=datetime.datetime.now()\n",
    "# concatenate both train and test datasets together\n",
    "X_all = np.concatenate((X_train, X_test), axis=0)\n",
    "X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09746116 0.07155445 0.06149531 0.05403385 0.04888934 0.04305227\n",
      " 0.03278262 0.02889642 0.02758364 0.0234214  0.02106689 0.02037553\n",
      " 0.01707064 0.0169402  0.01583382 0.01486345 0.01319358 0.01279014\n",
      " 0.01187272 0.01152937 0.0106604  0.01009794 0.00959151 0.00909635\n",
      " 0.00883287 0.00838818 0.00809832 0.00785718 0.00740262 0.00690014\n",
      " 0.00656144 0.0064547  0.00600819 0.00585612 0.00566754 0.00543471\n",
      " 0.00504717 0.00487079 0.00478955 0.00467594 0.00454369 0.00444918\n",
      " 0.00418217 0.00396164 0.00383708 0.00375785 0.00361426 0.00349025\n",
      " 0.00338732 0.00319696 0.00316854 0.00310145 0.0029648  0.00287101\n",
      " 0.00282514 0.00269423 0.00268392 0.00256509 0.00253168 0.00244648\n",
      " 0.00239702 0.00238581 0.00229234 0.00220949 0.0021306  0.00206317\n",
      " 0.00202781 0.00195035 0.00191471 0.00188549 0.00186976 0.00180104\n",
      " 0.00176787 0.00173358 0.00164849 0.00163237 0.00161407 0.00154303\n",
      " 0.00147019 0.00142197 0.00141014 0.00140144 0.00139602 0.00135022\n",
      " 0.00132368 0.0013189  0.00129196 0.00125168 0.00122524 0.00120413\n",
      " 0.00116358 0.00114311 0.00112544 0.00109857 0.0010833  0.00107167\n",
      " 0.0010368  0.00103411 0.0010057  0.00099923 0.00097645 0.00094101\n",
      " 0.00093553 0.00091145 0.00090033 0.00088919 0.00086086 0.00085227\n",
      " 0.00084065 0.00081628 0.00078547 0.00077631 0.00077387 0.00076336\n",
      " 0.00075984 0.00074702 0.00072854 0.00072351 0.00071423 0.00069946\n",
      " 0.00068959 0.0006854  0.00067454 0.0006684  0.00065816 0.0006378\n",
      " 0.0006303  0.00062351 0.00061717 0.00060011 0.00059397 0.00058903\n",
      " 0.00057799 0.00057705 0.00056991 0.00056288 0.00055801 0.00054632\n",
      " 0.00052806 0.00051367 0.00050493 0.00049424 0.00049031 0.00048653\n",
      " 0.00048142 0.00047374 0.00047125 0.00046239 0.00045692 0.00045248\n",
      " 0.00044416 0.00043706 0.00043113 0.00042553 0.00041788]\n",
      "[0.09746116 0.16901561 0.23051091 0.28454476 0.3334341  0.37648637\n",
      " 0.40926898 0.4381654  0.46574904 0.48917044 0.51023733 0.53061286\n",
      " 0.5476835  0.5646237  0.58045752 0.59532097 0.60851456 0.6213047\n",
      " 0.63317742 0.64470679 0.65536719 0.66546513 0.67505665 0.684153\n",
      " 0.69298586 0.70137405 0.70947236 0.71732954 0.72473217 0.73163231\n",
      " 0.73819375 0.74464845 0.75065664 0.75651276 0.7621803  0.767615\n",
      " 0.77266217 0.77753297 0.78232252 0.78699846 0.79154214 0.79599132\n",
      " 0.80017349 0.80413513 0.8079722  0.81173005 0.81534432 0.81883456\n",
      " 0.82222188 0.82541884 0.82858738 0.83168883 0.83465363 0.83752465\n",
      " 0.84034978 0.84304401 0.84572793 0.84829303 0.85082471 0.85327119\n",
      " 0.85566821 0.85805402 0.86034635 0.86255584 0.86468645 0.86674962\n",
      " 0.86877744 0.87072779 0.87264249 0.87452798 0.87639774 0.87819878\n",
      " 0.87996665 0.88170024 0.88334873 0.88498109 0.88659516 0.88813819\n",
      " 0.88960838 0.89103036 0.8924405  0.89384194 0.89523796 0.89658818\n",
      " 0.89791186 0.89923077 0.90052273 0.90177441 0.90299965 0.90420378\n",
      " 0.90536736 0.90651048 0.90763592 0.90873448 0.90981778 0.91088946\n",
      " 0.91192626 0.91296036 0.91396606 0.91496529 0.91594174 0.91688276\n",
      " 0.91781829 0.91872974 0.91963007 0.92051925 0.92138011 0.92223238\n",
      " 0.92307303 0.92388931 0.92467477 0.92545109 0.92622495 0.92698831\n",
      " 0.92774815 0.92849517 0.92922371 0.92994722 0.93066145 0.9313609\n",
      " 0.93205049 0.93273589 0.93341043 0.93407883 0.93473698 0.93537478\n",
      " 0.93600508 0.93662859 0.93724577 0.93784588 0.93843984 0.93902888\n",
      " 0.93960687 0.94018392 0.94075383 0.94131671 0.94187472 0.94242104\n",
      " 0.94294911 0.94346278 0.94396771 0.94446195 0.94495226 0.94543879\n",
      " 0.9459202  0.94639394 0.94686519 0.94732758 0.94778451 0.94823699\n",
      " 0.94868115 0.94911821 0.94954934 0.94997486 0.95039274]\n"
     ]
    }
   ],
   "source": [
    "# IT took about 10 seconds to run each individual PCA analysis\n",
    "# When components is 155 (which is less than 784), explained variability is 0.95039967\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=155)\n",
    "X_all_PCA = pca.fit_transform(X_all)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.859137\n"
     ]
    }
   ],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Using the identified principal components from step (2), \n",
    "## use the train.csv to build another random forest classifier. \n",
    "## Record the time it takes to fit the model and to evaluate the model on the test.csv data by submitting to Kaggle.com. Provide your Kaggle.com score and user ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID: michaelxiagang, score = 0.88728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 155)\n",
      "(28000, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=datetime.datetime.now()\n",
    "# Using generated PCA components to fit X\n",
    "X_train_PCA = X_all_PCA[0:42000]\n",
    "X_test_PCA  = X_all_PCA[42000:70000]\n",
    "print(X_train_PCA.shape)\n",
    "print(X_test_PCA.shape)\n",
    "clf.fit(X_train_PCA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data set \n",
    "# Result was submitted to Kaggle\n",
    "# ID: michaelxiagang, score = 0.93957\n",
    "y_pred=clf.predict(X_test_PCA)\n",
    "y_pred1 = pd.DataFrame(y_pred)\n",
    "y_pred1.index = y_pred1.index +1\n",
    "y_pred1.to_csv(\"Xia_Assignment5_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.317271\n"
     ]
    }
   ],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Submit both the RF Classifier and the PCA RF Classifier to Kaggle.com, \n",
    "## and report both scores along with your user name.  \n",
    "## I MUST have your user name to verify submission status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) The experiment we have proposed has a MAJOR design flaw. \n",
    "## Identify the flaw. Fix it. Rerun the experiment in a way that is consistent with a training-and-test regimen, \n",
    "## and submit this to Kaggle.com. Provide your Kaggle.com score and user ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If use standard scale for scaling data first before PCA analysis\n",
    "### ID: michaelxiagang, score = 0.86685\n",
    "\n",
    "## If use minmax scale for scaling data first before PCA analysis\n",
    "### ID: michaelxiagang, score = 0.88471\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.datetime.now()\n",
    "# Explainatory data needs to be scaled first. \n",
    "# Using standard scalar\n",
    "X_all = X_all.astype(np.float32)\n",
    "scalar = StandardScaler()\n",
    "scalar.fit(X_all)\n",
    "X_all_std = scalar.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05642717 0.04041234 0.03738277 0.02893004 0.02520754 0.02192549\n",
      " 0.01914282 0.01740686 0.01532232 0.01396087 0.01342177 0.01201422\n",
      " 0.01113962 0.01090584 0.01027987 0.00994955 0.00931257 0.00919635\n",
      " 0.008886   0.00863196 0.00821742 0.00798417 0.00762574 0.00742315\n",
      " 0.0071657  0.00689314 0.006814   0.00654589 0.00627294 0.00610346\n",
      " 0.00597261 0.00589304 0.00567359 0.00559358 0.00552473 0.00534443\n",
      " 0.00527594 0.00515842 0.00505499 0.00477438 0.00476312 0.00465155\n",
      " 0.00453454 0.00445757 0.00442313 0.00437877 0.00437293 0.00427724\n",
      " 0.00424808 0.00418524 0.0040406  0.00396258 0.00393176 0.00390562\n",
      " 0.00386444 0.00377501 0.00373883 0.00368328 0.00360377 0.0035637\n",
      " 0.00349288 0.00344527 0.00343239 0.00341    0.00334463 0.00332108\n",
      " 0.00329803 0.00319433 0.0031711  0.00315432 0.00309941 0.00305782\n",
      " 0.00305095 0.0030396  0.00296635 0.00292958 0.00291295 0.00290232\n",
      " 0.00288608 0.00287022 0.00284514 0.00281524 0.00279245 0.00278629\n",
      " 0.00278233 0.00276733 0.0027542  0.00272901 0.0026874  0.00268139\n",
      " 0.00267355 0.00263003 0.00262155 0.00258872 0.00258429 0.002571\n",
      " 0.002519   0.00250904 0.00248094 0.00244093 0.00243608 0.00241671\n",
      " 0.00238999 0.00236395 0.00235632 0.00232326 0.00229151 0.00225292\n",
      " 0.00223891 0.0022322  0.00219714 0.00219026 0.00215303 0.00213447\n",
      " 0.00210763 0.00210123 0.00206525 0.00205073 0.00202906 0.00198907\n",
      " 0.00197597 0.00196588 0.00195394 0.00194545 0.00192834 0.00191505\n",
      " 0.0018926  0.001884   0.00186304 0.0018189  0.00180676 0.00179009\n",
      " 0.00178407 0.00176999 0.00175853 0.0017478  0.00173304 0.001728\n",
      " 0.00169432 0.00167648 0.00165855 0.00164975 0.00164603 0.00164149\n",
      " 0.00161138 0.00160413 0.00158927 0.00156601 0.00156231 0.00154815\n",
      " 0.00153566 0.00152617 0.00151562 0.00149189 0.0014888  0.00147098\n",
      " 0.00146274 0.00144916 0.00144202 0.00142795 0.00142245 0.00142043\n",
      " 0.00140016 0.00139306 0.00139149 0.00139049 0.00138895 0.00138616\n",
      " 0.00138451 0.00136449 0.00135787 0.0013515  0.00134899 0.00133796\n",
      " 0.00132635 0.00131349 0.00129856 0.00129275 0.00128703 0.00127086\n",
      " 0.00126384 0.0012584  0.00123503 0.00122146 0.00121683 0.00121134\n",
      " 0.00119986 0.00119589 0.00117699 0.00117216 0.00116485 0.00115193\n",
      " 0.00114868 0.00114258 0.00113337 0.00112362 0.00110978 0.00108569\n",
      " 0.00108126 0.00106263 0.00105587 0.00104706 0.00104295 0.00102774\n",
      " 0.00101471 0.00100921 0.00099913 0.00099334 0.0009888  0.00097512\n",
      " 0.00096855 0.00096284 0.00095415 0.00094571 0.00094339 0.0009359\n",
      " 0.00092739 0.00090974 0.00090243 0.00089117 0.00088101 0.00087672\n",
      " 0.00087109 0.00086619 0.00085804 0.00085281 0.00084013 0.00082925\n",
      " 0.00082312 0.00081873 0.00081494 0.00080874 0.00080526 0.00079886\n",
      " 0.00078759 0.00078103 0.0007772  0.00077137 0.00075618 0.00075111\n",
      " 0.00074734 0.00073875 0.00073418 0.0007272  0.00072105 0.00071132\n",
      " 0.00070205 0.00070004 0.0006954  0.00068752 0.000682   0.00067842\n",
      " 0.00067579 0.00066256 0.00065992 0.0006586  0.00065215 0.00063904\n",
      " 0.00063695 0.00063532 0.00062967 0.00062515 0.00061774 0.00061589\n",
      " 0.00060767 0.00060294 0.00059648 0.00058662 0.00057969 0.00057486\n",
      " 0.00057216 0.00056982 0.00056344 0.00055823 0.00055572 0.00054787\n",
      " 0.00054506 0.00054064 0.00053996 0.00053701 0.00053145 0.00052447\n",
      " 0.00052095 0.00051512 0.0005111  0.00050846 0.0005017  0.00050082\n",
      " 0.00049545 0.00049327 0.00049051 0.00048775 0.00047839 0.00047512\n",
      " 0.00047177 0.00046906 0.00046531 0.0004557  0.00045099 0.0004451\n",
      " 0.00044474 0.00044252 0.00043768 0.00043116 0.00043019 0.00042702\n",
      " 0.00041813 0.0004159  0.00041249 0.00041174 0.00040692 0.00040454\n",
      " 0.00040084 0.00039821 0.00039654 0.00039085 0.00038773 0.00038399\n",
      " 0.00037898 0.00037645 0.00037576 0.00037545 0.00036953 0.00036446\n",
      " 0.00036125 0.0003582  0.00035435 0.0003502  0.00034683 0.00034507\n",
      " 0.00034425 0.00034039 0.00033455 0.00033046 0.00032576]\n",
      "[0.05642717 0.09683951 0.13422229 0.16315233 0.18835987 0.21028536\n",
      " 0.22942818 0.24683504 0.26215736 0.27611823 0.28953999 0.30155421\n",
      " 0.31269383 0.32359967 0.33387955 0.3438291  0.35314167 0.36233802\n",
      " 0.37122402 0.37985598 0.3880734  0.39605757 0.4036833  0.41110646\n",
      " 0.41827216 0.4251653  0.4319793  0.43852519 0.44479812 0.45090158\n",
      " 0.45687419 0.46276723 0.46844081 0.47403439 0.47955913 0.48490356\n",
      " 0.4901795  0.49533791 0.5003929  0.50516728 0.5099304  0.51458195\n",
      " 0.5191165  0.52357407 0.52799719 0.53237597 0.5367489  0.54102614\n",
      " 0.54527422 0.54945946 0.55350005 0.55746264 0.5613944  0.56530001\n",
      " 0.56916445 0.57293946 0.57667829 0.58036157 0.58396534 0.58752904\n",
      " 0.59102193 0.5944672  0.59789959 0.60130959 0.60465422 0.6079753\n",
      " 0.61127333 0.61446767 0.61763877 0.62079308 0.62389249 0.62695031\n",
      " 0.63000127 0.63304087 0.63600722 0.63893679 0.64184975 0.64475207\n",
      " 0.64763815 0.65050837 0.65335352 0.65616876 0.6589612  0.6617475\n",
      " 0.66452983 0.66729716 0.67005136 0.67278037 0.67546777 0.67814915\n",
      " 0.6808227  0.68345273 0.68607428 0.688663   0.69124729 0.69381829\n",
      " 0.69633729 0.69884633 0.70132727 0.70376819 0.70620427 0.70862098\n",
      " 0.71101097 0.71337492 0.71573124 0.7180545  0.72034601 0.72259893\n",
      " 0.72483784 0.72707005 0.72926718 0.73145744 0.73361047 0.73574494\n",
      " 0.73785257 0.7399538  0.74201906 0.74406979 0.74609884 0.74808792\n",
      " 0.75006389 0.75202977 0.75398371 0.75592916 0.7578575  0.75977255\n",
      " 0.76166515 0.76354915 0.76541219 0.7672311  0.76903785 0.77082794\n",
      " 0.77261201 0.77438199 0.77614052 0.77788832 0.77962136 0.78134936\n",
      " 0.78304369 0.78472016 0.78637871 0.78802847 0.7896745  0.79131599\n",
      " 0.79292737 0.7945315  0.79612077 0.79768678 0.79924908 0.80079723\n",
      " 0.80233289 0.80385906 0.80537468 0.80686657 0.80835538 0.80982636\n",
      " 0.81128909 0.81273825 0.81418027 0.81560821 0.81703066 0.81845109\n",
      " 0.81985125 0.82124431 0.8226358  0.82402629 0.82541524 0.82680141\n",
      " 0.82818591 0.8295504  0.83090827 0.83225977 0.83360876 0.83494672\n",
      " 0.83627308 0.83758656 0.83888512 0.84017787 0.8414649  0.84273576\n",
      " 0.8439996  0.845258   0.84649303 0.84771449 0.84893131 0.85014265\n",
      " 0.85134252 0.85253841 0.8537154  0.85488756 0.85605241 0.85720435\n",
      " 0.85835302 0.85949561 0.86062898 0.86175259 0.86286238 0.86394807\n",
      " 0.86502933 0.86609197 0.86714783 0.86819489 0.86923784 0.87026557\n",
      " 0.87128028 0.87228949 0.87328863 0.87428197 0.87527077 0.87624589\n",
      " 0.87721444 0.87817729 0.87913143 0.88007714 0.88102053 0.88195643\n",
      " 0.88288382 0.88379356 0.88469599 0.88558716 0.88646817 0.88734489\n",
      " 0.88821598 0.88908217 0.88994021 0.89079302 0.89163315 0.8924624\n",
      " 0.89328552 0.89410425 0.89491919 0.89572793 0.89653319 0.89733205\n",
      " 0.89811965 0.89890068 0.89967788 0.90044925 0.90120543 0.90195654\n",
      " 0.90270388 0.90344263 0.90417681 0.90490401 0.90562507 0.90633639\n",
      " 0.90703844 0.90773848 0.90843388 0.90912141 0.90980341 0.91048184\n",
      " 0.91115763 0.91182019 0.91248011 0.91313871 0.91379086 0.91442991\n",
      " 0.91506686 0.91570218 0.91633185 0.916957   0.91757473 0.91819062\n",
      " 0.9187983  0.91940123 0.91999771 0.92058433 0.92116402 0.92173888\n",
      " 0.92231104 0.92288085 0.9234443  0.92400253 0.92455825 0.92510612\n",
      " 0.92565118 0.92619182 0.92673178 0.92726879 0.92780023 0.92832471\n",
      " 0.92884566 0.92936078 0.92987188 0.93038034 0.93088203 0.93138285\n",
      " 0.9318783  0.93237157 0.93286208 0.93334983 0.93382822 0.93430334\n",
      " 0.93477511 0.93524417 0.93570948 0.93616517 0.93661617 0.93706127\n",
      " 0.937506   0.93794852 0.9383862  0.93881736 0.93924755 0.93967457\n",
      " 0.9400927  0.9405086  0.94092109 0.94133282 0.94173975 0.94214428\n",
      " 0.94254512 0.94294333 0.94333987 0.94373072 0.94411845 0.94450245\n",
      " 0.94488143 0.94525788 0.94563363 0.94600909 0.94637862 0.94674308\n",
      " 0.94710432 0.94746253 0.94781688 0.94816708 0.94851391 0.94885898\n",
      " 0.94920323 0.94954363 0.94987817 0.95020863 0.9505344 ]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=335)\n",
    "pca.fit(X_all_std)\n",
    "X_all_std_PCA = pca.fit_transform(X_all_std)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 155)\n",
      "(28000, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using generated PCA components to fit X\n",
    "X_train_std_PCA = X_all_std_PCA[0:42000]\n",
    "X_test_std_PCA  = X_all_std_PCA[42000:70000]\n",
    "print(X_train_PCA.shape)\n",
    "print(X_test_PCA.shape)\n",
    "clf.fit(X_train_std_PCA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data set \n",
    "# Result was submitted to Kaggle\n",
    "y_pred=clf.predict(X_test_std_PCA)\n",
    "y_pred1 = pd.DataFrame(y_pred)\n",
    "y_pred1.index = y_pred1.index +1\n",
    "y_pred1.to_csv(\"Xia_Assignment5_5_std.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainatory data needs to be scaled first. \n",
    "# Using min max scalar\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X_all)\n",
    "X_all_minmax = scalar.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09745818 0.07155215 0.06149336 0.05403214 0.04888773 0.04305095\n",
      " 0.0327816  0.02889551 0.02758275 0.02342069 0.02106623 0.02037491\n",
      " 0.01707012 0.01693969 0.01583332 0.01486301 0.01319318 0.01278977\n",
      " 0.01187235 0.01152902 0.01066008 0.01009764 0.00959122 0.00909608\n",
      " 0.0088326  0.00838793 0.00809807 0.00785694 0.0074024  0.00689994\n",
      " 0.00656125 0.00645451 0.00600801 0.00585594 0.00566736 0.00543454\n",
      " 0.00504702 0.00487065 0.00478941 0.0046758  0.00454355 0.00444905\n",
      " 0.00418204 0.00396152 0.00383696 0.00375774 0.00361416 0.00349014\n",
      " 0.00338722 0.00319687 0.00316845 0.00310136 0.00296471 0.00287093\n",
      " 0.00282505 0.00269415 0.00268384 0.00256502 0.0025316  0.00244641\n",
      " 0.00239695 0.00238574 0.00229227 0.00220942 0.00213054 0.00206311\n",
      " 0.00202775 0.00195029 0.00191465 0.00188544 0.0018697  0.00180099\n",
      " 0.00176782 0.00173353 0.00164844 0.00163232 0.00161403 0.00154299\n",
      " 0.00147015 0.00142195 0.00141011 0.00140141 0.00139599 0.0013502\n",
      " 0.00132366 0.00131888 0.00129191 0.00125164 0.00122525 0.00120413\n",
      " 0.00116355 0.00114309 0.00112537 0.00109851 0.00108333 0.0010716\n",
      " 0.00103685 0.0010341  0.00100579 0.00099916 0.00097648 0.00094137\n",
      " 0.0009357  0.0009112  0.0009005  0.00088926 0.00086132 0.00085219\n",
      " 0.00084038 0.00081693 0.00078501 0.0007765  0.00077532 0.00076365\n",
      " 0.0007595  0.0007471  0.00072856 0.00072404 0.00071447 0.00070196\n",
      " 0.00069024 0.00068517 0.00067643 0.00066998 0.00065912 0.00063913\n",
      " 0.00062954 0.00062445 0.00061346 0.00059687 0.00059649 0.00058938\n",
      " 0.00058086 0.00058012 0.00057015 0.00056658 0.00055157 0.00054638\n",
      " 0.00052676 0.00052041 0.00051171 0.00049866 0.00049251 0.0004881\n",
      " 0.00048699 0.0004862  0.00047405 0.00046685 0.00045883 0.0004542\n",
      " 0.00045235 0.00044535 0.0004406  0.00043261 0.00041981]\n",
      "[0.09745818 0.16901033 0.23050368 0.28453582 0.33342355 0.37647451\n",
      " 0.4092561  0.43815161 0.46573436 0.48915506 0.51022129 0.5305962\n",
      " 0.54766632 0.56460601 0.58043933 0.59530234 0.60849552 0.62128529\n",
      " 0.63315764 0.64468666 0.65534674 0.66544437 0.67503559 0.68413167\n",
      " 0.69296427 0.7013522  0.70945027 0.71730722 0.72470961 0.73160956\n",
      " 0.7381708  0.74462532 0.75063332 0.75648927 0.76215663 0.76759117\n",
      " 0.77263819 0.77750884 0.78229825 0.78697405 0.7915176  0.79596665\n",
      " 0.80014869 0.80411021 0.80794717 0.81170491 0.81531906 0.81880921\n",
      " 0.82219642 0.82539329 0.82856174 0.83166309 0.83462781 0.83749874\n",
      " 0.84032379 0.84301794 0.84570178 0.8482668  0.8507984  0.85324481\n",
      " 0.85564176 0.8580275  0.86031977 0.86252919 0.86465973 0.86672284\n",
      " 0.8687506  0.87070089 0.87261554 0.87450097 0.87637068 0.87817166\n",
      " 0.87993948 0.88167301 0.88332145 0.88495377 0.8865678  0.8881108\n",
      " 0.88958095 0.8910029  0.89241301 0.89381442 0.89521041 0.89656061\n",
      " 0.89788426 0.89920314 0.90049505 0.90174669 0.90297193 0.90417606\n",
      " 0.90533961 0.9064827  0.90760807 0.90870659 0.90978992 0.91086152\n",
      " 0.91189836 0.91293246 0.91393824 0.9149374  0.91591389 0.91685526\n",
      " 0.91779096 0.91870216 0.91960266 0.92049192 0.92135324 0.92220543\n",
      " 0.92304581 0.92386273 0.92464774 0.92542424 0.92619956 0.92696321\n",
      " 0.92772271 0.92846981 0.92919837 0.92992241 0.93063688 0.93133883\n",
      " 0.93202907 0.93271424 0.93339067 0.93406065 0.93471977 0.9353589\n",
      " 0.93598844 0.93661289 0.93722635 0.93782322 0.9384197  0.93900909\n",
      " 0.93958995 0.94017006 0.94074022 0.94130679 0.94185836 0.94240475\n",
      " 0.94293151 0.94345192 0.94396363 0.94446229 0.9449548  0.9454429\n",
      " 0.94592989 0.94641609 0.94689013 0.94735698 0.94781582 0.94827001\n",
      " 0.94872236 0.94916771 0.94960831 0.95004092 0.95046073]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=155)\n",
    "pca.fit(X_all_minmax)\n",
    "X_all_minmax_PCA = pca.fit_transform(X_all_minmax)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 155)\n",
      "(28000, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using generated PCA components to fit X\n",
    "X_train_minmax_PCA = X_all_minmax_PCA[0:42000]\n",
    "X_test_minmax_PCA  = X_all_minmax_PCA[42000:70000]\n",
    "print(X_train_PCA.shape)\n",
    "print(X_test_PCA.shape)\n",
    "clf.fit(X_train_minmax_PCA, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using test data set \n",
    "# Result was submitted to Kaggle\n",
    "# ID: michaelxiagang, score = 0.93957\n",
    "y_pred=clf.predict(X_test_minmax_PCA)\n",
    "y_pred1 = pd.DataFrame(y_pred)\n",
    "y_pred1.index = y_pred1.index +1\n",
    "y_pred1.to_csv(\"Xia_Assignment5_5_minmax.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:45.256914\n"
     ]
    }
   ],
   "source": [
    "end=datetime.datetime.now()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
